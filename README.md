# ECG Arrhythmia Classifier (MIT-BIH)

**Reproducible signal-processing â†’ ML pipeline** for beat-level arrhythmia classification from raw MIT-BIH ECG recordings (PhysioNet).

---

## TL;DR

* Languages / libs: **Python, NumPy, SciPy, scikit-learn, wfdb, imbalanced-learn, pandas, matplotlib**
* What it does: Loads raw MITâ€‘BIH records, applies robust filtering and QRS detection, extracts beat-level morphological & RR features, trains a RandomForest classifier with **5-fold StratifiedGroupKFold** (subject-wise folds), and exports a deployable pipeline plus evaluation artifacts.
* Example results (from my run): **91.71% mean accuracy**, **0.5807 macroâ€‘F1**; detector **PPV 97.44%** (median 99.74%), **sensitivity 88.00%** (median 96.90%).

---

## ðŸ“Š Results Summary

| Component                    | Metric          | Mean       | StdDev | Median     |
| ---------------------------- | --------------- | ---------- | ------ | ---------- |
| **Classifier (5-Fold CV)**   | Accuracy        | **91.71%** | Â±4.17% | â€”          |
|                              | Macroâ€‘F1        | **0.5807** | Â±0.038 | â€”          |
|                              | Macroâ€‘Precision | **0.6643** | Â±0.123 | â€”          |
| **Detector (Panâ€“Tompkins+)** | PPV             | **97.44%** | â€”      | **99.74%** |
|                              | Sensitivity     | **88.00%** | â€”      | **96.90%** |

These metrics are derived from `cv_metrics_summary.csv` (classifier) and the detector evaluation CSV generated in `results/eval_outputs/analysis/`.

---

## Repository structure

```
.
â”œâ”€â”€ README.md                        # (this file)
â”œâ”€â”€ requirements.txt                 # pinned python deps
â”œâ”€â”€ run.py                           # training & evaluation orchestrator
â”œâ”€â”€ src/                             # project source code
â”‚   â”œâ”€â”€ data_loader.py               # loads local PhysioNet files
â”‚   â”œâ”€â”€ signal_processor.py          # filtering + Pan-Tompkins detector
â”‚   â”œâ”€â”€ feature_extractor.py         # beat-level feature extraction
â”‚   â”œâ”€â”€ ml_trainer.py                # Group-CV, oversampling, model export
â”‚   â””â”€â”€ visualizer.py                # plotting helpers
â”œâ”€â”€ eval/                            # evaluation & inference scripts
â”‚   â”œâ”€â”€ infer_on_record.py
â”‚   â”œâ”€â”€ infer_on_feature_csv.py
â”‚   â”œâ”€â”€ analyze_detector.py
â”‚   â””â”€â”€ visualize_predictions.py
â”œâ”€â”€ data/                            # **NOT** committed: MIT-BIH .dat/.hea/.atr files
â””â”€â”€ outputs/                         # outputs (ignored by default; optional LFS for models)
    â”œâ”€â”€ plots/
    â”œâ”€â”€ models/
    â””â”€â”€ eval_outputs/
```

---

## Quick setup

```bash
# create venv
python -m venv .venv
. .venv/bin/activate

# install packages
pip install -r requirements.txt
```

`requirements.txt` is pinned for reproducibility (numPy, SciPy, scikit-learn, wfdb, pandas, imbalanced-learn, matplotlib, joblib, tqdm).

---

## Prepare the dataset (MIT-BIH)

1. Download the MITâ€‘BIH Arrhythmia Database from PhysioNet: [https://physionet.org/content/mitdb/](https://physionet.org/content/mitdb/)
2. Place the downloaded files in `data/` so each record has `.dat`, `.hea`, `.atr` files, e.g. `data/100.dat`, `data/100.hea`, `data/100.atr`.

**Do not** commit raw dataset files to GitHub; keep `data/` in `.gitignore`.

---

## Run training & evaluation

Train the model and produce evaluation artifacts (confusion matrix, per-fold metrics, final pipeline):

```bash
python run.py
```

Outputs are saved under `results/`:

* `results/plots/confusion_matrix.png` â€” normalized (per-row) confusion matrix from out-of-fold predictions.
* `results/plots/cv_metrics_summary.csv` â€” per-fold accuracy/precision/recall/F1 and Mean/Std rows.
* `results/models/arrhythmia_classifier_pipeline.joblib` â€” compressed scikit-learn Pipeline (scaler + RandomForest).
* `results/metadata.json` â€” experiment config, filter params, feature names, seed, package versions.

---

## Evaluation & inference

There are helper scripts in `eval/`.

**Detector analysis** (Panâ€‘Tompkins performance):

```bash
python eval/analyze_detector.py
# writes results/eval_outputs/analysis/detector_summary_tol50ms.csv
```

**Inference on a single MIT-BIH record (uses annotation for ground truth)**:

```bash
python eval/infer_on_record.py
# writes results/eval_outputs/inference/<record>_predictions.csv and classification report
```

**Predict on a CSV of precomputed features**:

```bash
# Prepare data/features_to_predict.csv with columns exactly matching FEATURE_NAMES in src/feature_extractor.py
python eval/infer_on_feature_csv.py
# writes results/eval_outputs/inference/features_to_predict_preds.csv
```

**Visualize example beat windows with predictions**:

```bash
python eval/visualize_predictions.py
# writes results/eval_outputs/visualizations/<record>_example_beats.png
```

---

## Feature names & units

```text
rr_pre_ms               # milliseconds (ms)
rr_post_ms              # milliseconds (ms)
qrs_amplitude_max_mv    # millivolts (mV)
qrs_amplitude_min_mv    # millivolts (mV)
qrs_area_mvs            # mV * s
qrs_width_ms            # ms (approx. half-max width)
qrs_max_slope_mv_per_s  # mv/s
qrs_spectral_entropy    # unitless (bits)
```

Maintaining order & units is crucial when constructing feature CSVs for `infer_on_feature_csv.py` or when re-training.

---

## Reproducibility

* `metadata.json` records seed, filter params, feature names, package versions â€” include it alongside results for auditability.
* Use the pinned `requirements.txt` to recreate the same environment.
* The CV loop uses `StratifiedGroupKFold` (fallback to `GroupKFold` if not available) to prevent subject leakage.

---

## License

Include a `LICENSE` file (MIT recommended for academic code). Replace `YEAR` and `Your Name` as appropriate.

---

## Contact

Email id: â€” `kushkapoor.kk1234@gmail.com`

---

## Acknowledgements / Data citation

MIT-BIH Arrhythmia Database: Goldberger AL et al., PhysioBank, PhysioToolkit, and PhysioNet: Components of a new research resource for complex physiologic signals. Circulation 2000;101(23):e215â€“e220.

---

*End of README*
